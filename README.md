# Alphabet-Detection
Alphabet detection identifies and classifies hand gestures representing letters, enabling recognition of sign language alphabets. Using computer vision and deep learning models like YOLO and LSTM, it translates visual inputs into corresponding alphabetic characters for accessibility and communication.

# âœ¨ Features
ğŸ” Real-time alphabet gesture detection
âš¡ Fast & lightweight YOLOv8 model
ğŸ¥ Supports images, videos, and webcam input
ğŸ›  Easy to run and customize
ğŸ“ˆ Pre-trained on a custom sign language alphabet dataset

2.Install dependencies
pip install -r requirements.txt

3.Ensure model weights are available
Place your trained weights (best.pt) in the project folder.

ğŸš€ Usage
Run Detection
python try.py

Evaluate Model
python evaluate_yolo.py

ğŸ“‚ Project Structure
alphabetsDetection/
â”‚-- try.py                # Main detection script
â”‚-- evaluate_yolo.py      # Model evaluation
â”‚-- requirements.txt      # Python dependencies
â”‚-- yolov8n.pt             # YOLOv8 base model
â”‚-- best.pt                # Trained weights for alphabet detection
â”‚-- runs/                  # Training results and logs
ğŸ“Š Model Details
Base Model: YOLOv8n

Framework: Python, PyTorch

Training Data: Custom alphabet gesture dataset

Output: Predicted alphabet with bounding box & confidence score
